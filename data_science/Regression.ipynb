{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ho44013/machine_study/blob/main/data_science/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBkGlL7-JBun"
      },
      "source": [
        "# 1. Linear Regression Practice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1CQvAFx-vr0",
        "outputId": "117d499d-23a4-4585-9cda-af09e36d974f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "y =  tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Size:  2\n",
            "Shape:  torch.Size([3, 3])\n",
            "차원(랭크):  2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
        "y = torch.FloatTensor([[1,2,3], [4,5,6]])\n",
        "\n",
        "print(\"x = \", x)\n",
        "print(\"y = \", y)\n",
        "print(\"Size: \", len(x.size()))\n",
        "print(\"Shape: \", x.shape)\n",
        "print(\"차원(랭크): \", x.ndimension())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LwVRteZD6tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4439147-77ce-4ad5-b657-cda627b96457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0.shape:  torch.Size([1, 3, 3])\n",
            "x1.shape: torch.Size([3, 1, 3])\n",
            "x2.shape: torch.Size([3, 3, 1])\n",
            "x0 = tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "x1 = tensor([[[1, 2, 3]],\n",
            "\n",
            "        [[4, 5, 6]],\n",
            "\n",
            "        [[7, 8, 9]]])\n",
            "x2 = tensor([[[1],\n",
            "         [2],\n",
            "         [3]],\n",
            "\n",
            "        [[4],\n",
            "         [5],\n",
            "         [6]],\n",
            "\n",
            "        [[7],\n",
            "         [8],\n",
            "         [9]]])\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.unsqueeze(x, 0)\n",
        "x1 = torch.unsqueeze(x, 1)\n",
        "x2 = torch.unsqueeze(x, 2)\n",
        "print(\"x0.shape: \", x0.shape)\n",
        "print(\"x1.shape:\", x1.shape)\n",
        "print(\"x2.shape:\", x2.shape)\n",
        "print(\"x0 =\", x0)\n",
        "print(\"x1 =\", x1)\n",
        "print(\"x2 =\", x2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = torch.squeeze(x0)\n",
        "print(\"x3 = \", x3)\n",
        "print(\"x3.shape = \", x3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n5xl0JnK-CJ",
        "outputId": "bb2bfb94-f624-4516-82f8-412668edcdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x3 =  tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "x3.shape =  torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x4 = x.view(9)\n",
        "x5 = x.view(1, 3, 3)\n",
        "print(\"x4 = \", x4)\n",
        "print(\"x5 = \", x5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1CEhaRmLOwv",
        "outputId": "fb339a83-9ba6-48d2-b470-5e2e7825f79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x4 =  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "x5 =  tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([[1,2], [3,4], [5,6]])\n",
        "w = torch.randn(1,2, dtype=torch.float)\n",
        "b = torch.randn(3,1, dtype=torch.float)\n",
        "\n",
        "result = x @ torch.t(w) + b\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fThudL5MLYcJ",
        "outputId": "fe2554ef-2814-4d26-b43a-8b2593636fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0946],\n",
            "        [-0.7188],\n",
            "        [-2.6790]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "a = w*3\n",
        "l = a**2\n",
        "l.backward()\n",
        "\n",
        "print('l을 w로 미분한 값은', w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVluYeLzMVdW",
        "outputId": "93930567-b543-4b82-d066-2ac5f479ceee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l을 w로 미분한 값은 tensor(18.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1,2], [3,2], [3,7], [1,1], [1,0]])\n",
        "y_train = torch.FloatTensor([[4], [8], [23], [1], [-2]])\n",
        "\n",
        "W = torch.randn(2,1)\n",
        "b = torch.randn(1,1)\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(3001):\n",
        "  W.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  hypothesis = torch.mm(x_train, W) + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  cost.backward()\n",
        "  with torch.no_grad() as grd:\n",
        "    W = W - lr * W.grad\n",
        "    b = b - lr * b.grad\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"epoch: {epoch}, cost: {cost:.6f}, W: {W.squeeze()}, b: {b}\")\n",
        "\n",
        "x_test = torch.FloatTensor([[5, 10]])\n",
        "test_result = torch.mm(x_test, W) + b\n",
        "print(test_result.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRcZNHdhMcaX",
        "outputId": "63223f1c-039d-4ead-c983-543647687b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0511],\n",
            "        [ 0.9600]]) tensor([[-0.6418]])\n",
            "epoch: 0, cost: 103.573708, W: tensor([-0.6709,  1.6382]), b: tensor([[-0.5012]])\n",
            "epoch: 100, cost: 1.542468, W: tensor([0.4680, 3.2545]), b: tensor([[-1.3941]])\n",
            "epoch: 200, cost: 0.790740, W: tensor([0.8766, 3.2007]), b: tensor([[-2.1493]])\n",
            "epoch: 300, cost: 0.406350, W: tensor([1.1918, 3.1460]), b: tensor([[-2.6752]])\n",
            "epoch: 400, cost: 0.208831, W: tensor([1.4203, 3.1049]), b: tensor([[-3.0505]])\n",
            "epoch: 500, cost: 0.107322, W: tensor([1.5844, 3.0752]), b: tensor([[-3.3194]])\n",
            "epoch: 600, cost: 0.055155, W: tensor([1.7021, 3.0539]), b: tensor([[-3.5121]])\n",
            "epoch: 700, cost: 0.028345, W: tensor([1.7864, 3.0387]), b: tensor([[-3.6502]])\n",
            "epoch: 800, cost: 0.014567, W: tensor([1.8469, 3.0277]), b: tensor([[-3.7492]])\n",
            "epoch: 900, cost: 0.007486, W: tensor([1.8902, 3.0199]), b: tensor([[-3.8202]])\n",
            "epoch: 1000, cost: 0.003847, W: tensor([1.9213, 3.0142]), b: tensor([[-3.8711]])\n",
            "epoch: 1100, cost: 0.001977, W: tensor([1.9436, 3.0102]), b: tensor([[-3.9076]])\n",
            "epoch: 1200, cost: 0.001016, W: tensor([1.9596, 3.0073]), b: tensor([[-3.9338]])\n",
            "epoch: 1300, cost: 0.000522, W: tensor([1.9710, 3.0052]), b: tensor([[-3.9525]])\n",
            "epoch: 1400, cost: 0.000268, W: tensor([1.9792, 3.0038]), b: tensor([[-3.9660]])\n",
            "epoch: 1500, cost: 0.000138, W: tensor([1.9851, 3.0027]), b: tensor([[-3.9756]])\n",
            "epoch: 1600, cost: 0.000071, W: tensor([1.9893, 3.0019]), b: tensor([[-3.9825]])\n",
            "epoch: 1700, cost: 0.000036, W: tensor([1.9923, 3.0014]), b: tensor([[-3.9875]])\n",
            "epoch: 1800, cost: 0.000019, W: tensor([1.9945, 3.0010]), b: tensor([[-3.9910]])\n",
            "epoch: 1900, cost: 0.000010, W: tensor([1.9961, 3.0007]), b: tensor([[-3.9936]])\n",
            "epoch: 2000, cost: 0.000005, W: tensor([1.9972, 3.0005]), b: tensor([[-3.9954]])\n",
            "epoch: 2100, cost: 0.000003, W: tensor([1.9980, 3.0004]), b: tensor([[-3.9967]])\n",
            "epoch: 2200, cost: 0.000001, W: tensor([1.9986, 3.0003]), b: tensor([[-3.9976]])\n",
            "epoch: 2300, cost: 0.000001, W: tensor([1.9990, 3.0002]), b: tensor([[-3.9983]])\n",
            "epoch: 2400, cost: 0.000000, W: tensor([1.9993, 3.0001]), b: tensor([[-3.9988]])\n",
            "epoch: 2500, cost: 0.000000, W: tensor([1.9995, 3.0001]), b: tensor([[-3.9991]])\n",
            "epoch: 2600, cost: 0.000000, W: tensor([1.9996, 3.0001]), b: tensor([[-3.9994]])\n",
            "epoch: 2700, cost: 0.000000, W: tensor([1.9997, 3.0000]), b: tensor([[-3.9995]])\n",
            "epoch: 2800, cost: 0.000000, W: tensor([1.9998, 3.0000]), b: tensor([[-3.9997]])\n",
            "epoch: 2900, cost: 0.000000, W: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n",
            "epoch: 3000, cost: 0.000000, W: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n",
            "35.999839782714844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = [[1, 2, 7], [3, 2, 5], [3, 7, 2], [1, 1, 1], [1, 0, -5]]\n",
        "y = [[4], [8], [23], [1], [-2]]\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(x, y)\n",
        "\n",
        "print(lr.coef_, lr.intercept_)\n",
        "print(lr.predict([[5, 10, 10]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXCQY9s6Nnuq",
        "outputId": "98923510-5edf-4cc0-c320-69efb0891cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3. 0.]] [-4.]\n",
            "[[36.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Logistic Regression Practice"
      ],
      "metadata": {
        "id": "Ird3LY8HOzlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "W = torch.rand(1,1)\n",
        "b = torch.rand(1,1)\n",
        "\n",
        "lr = 1.0\n",
        "\n",
        "for epoch in range(3001):\n",
        "  W.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, W) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  cost.backward()\n",
        "  with torch.no_grad() as grd:\n",
        "    W = W - lr * W.grad\n",
        "    b = b - lr * b.grad\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"epoch: {epoch}, cost: {cost:.6f}, W: {W.squeeze():.6f}, b: {b.squeeze():.6f}\")\n",
        "\n",
        "x_test = torch.FloatTensor([[4.5], [1.1]])\n",
        "test_result = torch.sigmoid(torch.mm(x_test, W) + b)\n",
        "print(torch.round(test_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5K4D-ZaO5LN",
        "outputId": "15a0ad31-ba8c-41b6-e4f7-a2261866bb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 0.743404, W: -0.357853, b: 0.012425\n",
            "epoch: 100, cost: 0.420165, W: -1.452150, b: 4.409600\n",
            "epoch: 200, cost: 0.398705, W: -1.898918, b: 5.775224\n",
            "epoch: 300, cost: 0.390813, W: -2.174649, b: 6.610539\n",
            "epoch: 400, cost: 0.387005, W: -2.367565, b: 7.192312\n",
            "epoch: 500, cost: 0.384922, W: -2.510805, b: 7.623068\n",
            "epoch: 600, cost: 0.383697, W: -2.620919, b: 7.953582\n",
            "epoch: 700, cost: 0.382943, W: -2.707509, b: 8.213139\n",
            "epoch: 800, cost: 0.382462, W: -2.776686, b: 8.420290\n",
            "epoch: 900, cost: 0.382149, W: -2.832593, b: 8.587576\n",
            "epoch: 1000, cost: 0.381941, W: -2.878172, b: 8.723877\n",
            "epoch: 1100, cost: 0.381801, W: -2.915580, b: 8.835689\n",
            "epoch: 1200, cost: 0.381706, W: -2.946442, b: 8.927902\n",
            "epoch: 1300, cost: 0.381641, W: -2.972012, b: 9.004277\n",
            "epoch: 1400, cost: 0.381596, W: -2.993268, b: 9.067752\n",
            "epoch: 1500, cost: 0.381565, W: -3.010989, b: 9.120659\n",
            "epoch: 1600, cost: 0.381543, W: -3.025795, b: 9.164855\n",
            "epoch: 1700, cost: 0.381528, W: -3.038186, b: 9.201839\n",
            "epoch: 1800, cost: 0.381517, W: -3.048573, b: 9.232836\n",
            "epoch: 1900, cost: 0.381509, W: -3.057289, b: 9.258845\n",
            "epoch: 2000, cost: 0.381504, W: -3.064613, b: 9.280697\n",
            "epoch: 2100, cost: 0.381500, W: -3.070772, b: 9.299073\n",
            "epoch: 2200, cost: 0.381497, W: -3.075955, b: 9.314537\n",
            "epoch: 2300, cost: 0.381495, W: -3.080320, b: 9.327558\n",
            "epoch: 2400, cost: 0.381494, W: -3.083996, b: 9.338526\n",
            "epoch: 2500, cost: 0.381493, W: -3.087095, b: 9.347768\n",
            "epoch: 2600, cost: 0.381492, W: -3.089708, b: 9.355563\n",
            "epoch: 2700, cost: 0.381492, W: -3.091911, b: 9.362135\n",
            "epoch: 2800, cost: 0.381492, W: -3.093770, b: 9.367681\n",
            "epoch: 2900, cost: 0.381491, W: -3.095339, b: 9.372360\n",
            "epoch: 3000, cost: 0.381491, W: -3.096664, b: 9.376310\n",
            "tensor([[0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3], [4], [5], [2.5], [3.5], [0], [3.1], [2.7], [2.8], [2.9]])\n",
        "y_train = torch.FloatTensor([[1], [1], [1], [0], [0], [0], [0], [1], [0], [1], [1], [1]])\n",
        "\n",
        "W = torch.randn(1, 1, requires_grad=True)\n",
        "b = torch.randn(1, 1, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD([W,b], lr=1.0)\n",
        "# optimizer = torch.optim.Adam([W,b], lr=0.1)\n",
        "# optimizer = torch.optim.Adadelta([W,b])\n",
        "# optimizer = torch.optim.Adagrad([W,b], lr=1)\n",
        "# # 이 optimizer는 값이 이상하게 나오던데 왜인지는 모르겠음\n",
        "# optimizer = torch.optim.RMSprop([W,b])\n",
        "\n",
        "\n",
        "for epoch in range(3001):\n",
        "    h = torch.sigmoid(x_train @ W + b)\n",
        "    cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad() as grd:\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"epoch: {epoch}, cost: {cost:.6f}, W: {W.squeeze():.6f}, b: {b.squeeze():.6f}\")\n"
      ],
      "metadata": {
        "id": "HnmAbqjzuTnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f908c1-7595-4ba5-afd8-a54fc368a219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 0.954234, W: 0.522286, b: -0.577692\n",
            "epoch: 100, cost: 0.422561, W: -1.415626, b: 4.297308\n",
            "epoch: 200, cost: 0.399415, W: -1.878766, b: 5.713975\n",
            "epoch: 300, cost: 0.391127, W: -2.161164, b: 6.569797\n",
            "epoch: 400, cost: 0.387169, W: -2.357791, b: 7.162883\n",
            "epoch: 500, cost: 0.385016, W: -2.503402, b: 7.600829\n",
            "epoch: 600, cost: 0.383754, W: -2.615155, b: 7.936296\n",
            "epoch: 700, cost: 0.382978, W: -2.702938, b: 8.199444\n",
            "epoch: 800, cost: 0.382485, W: -2.773010, b: 8.409286\n",
            "epoch: 900, cost: 0.382164, W: -2.829610, b: 8.578652\n",
            "epoch: 1000, cost: 0.381951, W: -2.875730, b: 8.716578\n",
            "epoch: 1100, cost: 0.381808, W: -2.913569, b: 8.829680\n",
            "epoch: 1200, cost: 0.381711, W: -2.944781, b: 8.922938\n",
            "epoch: 1300, cost: 0.381644, W: -2.970634, b: 9.000160\n",
            "epoch: 1400, cost: 0.381598, W: -2.992121, b: 9.064326\n",
            "epoch: 1500, cost: 0.381566, W: -3.010030, b: 9.117795\n",
            "epoch: 1600, cost: 0.381544, W: -3.024992, b: 9.162457\n",
            "epoch: 1700, cost: 0.381528, W: -3.037513, b: 9.199830\n",
            "epoch: 1800, cost: 0.381517, W: -3.048008, b: 9.231152\n",
            "epoch: 1900, cost: 0.381510, W: -3.056816, b: 9.257432\n",
            "epoch: 2000, cost: 0.381504, W: -3.064215, b: 9.279510\n",
            "epoch: 2100, cost: 0.381500, W: -3.070438, b: 9.298076\n",
            "epoch: 2200, cost: 0.381497, W: -3.075674, b: 9.313697\n",
            "epoch: 2300, cost: 0.381496, W: -3.080081, b: 9.326847\n",
            "epoch: 2400, cost: 0.381494, W: -3.083796, b: 9.337929\n",
            "epoch: 2500, cost: 0.381493, W: -3.086927, b: 9.347267\n",
            "epoch: 2600, cost: 0.381492, W: -3.089566, b: 9.355142\n",
            "epoch: 2700, cost: 0.381492, W: -3.091792, b: 9.361779\n",
            "epoch: 2800, cost: 0.381492, W: -3.093670, b: 9.367381\n",
            "epoch: 2900, cost: 0.381491, W: -3.095256, b: 9.372110\n",
            "epoch: 3000, cost: 0.381491, W: -3.096593, b: 9.376101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "\n",
        "plt.scatter(x_train, y_train, c=\"black\")\n",
        "X = torch.linspace(0,5,100).unsqueeze(1)\n",
        "Y = torch.sigmoid(torch.mm(X,W)+b)\n",
        "plt.plot(X, Y, c=\"#ff0000\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Kr2-yIJJxV4U",
        "outputId": "0e29f0fc-0e4f-496b-d6eb-e029dc8c2500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train = [[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]]\n",
        "y_train = [1,1,1,0,0,0,0,1,0,1,1,1]\n",
        "\n",
        "model = LogisticRegression(penalty=None)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "print(model.coef_, model.intercept_)\n",
        "\n",
        "x_test = [[4.5],[1.1]]\n",
        "test_result = model.predict(x_test)\n",
        "print(test_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxjCwUsaxgvW",
        "outputId": "bdd858a4-6cdd-4ed3-e797-366d25cc1bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.10385806]] [9.39776831]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Softmax Regression Practice"
      ],
      "metadata": {
        "id": "Zx-h-j7k2RoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5],\n",
        "                            [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
        "y_train = torch.FloatTensor([[0,0,1], [0,0,1], [0,0,1], [0,1,0],\n",
        "                            [0,1,0], [0,1,0], [1,0,0], [1,0,0]])\n",
        "\n",
        "W = torch.rand(4, 3, requires_grad=True)\n",
        "b = torch.rand(1, 3, requires_grad=True)\n",
        "optimizer = torch.optim.Adam([W,b], lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    h = torch.softmax(torch.mm(x_train, W) + b, dim=1)\n",
        "    cost = -torch.mean(torch.sum(y_train * torch.log(h), dim=1))\n",
        "\n",
        "    # h = (torch.mm(x_train, W) + b).softmax(dim=1)\n",
        "    # cost = -(y_train * torch.log(h)).sum(dim=1).mean()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      if epoch % 100 == 0:\n",
        "        print(f\"epoch: {epoch}, cost: {cost.item()}\")\n",
        "\n",
        "print(torch.argmax(h, dim= 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rnaFN9u2WKy",
        "outputId": "c62fe739-b7f8-4fc1-bf44-fbb4f081480b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 1.0926320552825928\n",
            "epoch: 100, cost: 0.26102447509765625\n",
            "epoch: 200, cost: 0.15212231874465942\n",
            "epoch: 300, cost: 0.0998399555683136\n",
            "epoch: 400, cost: 0.0709516853094101\n",
            "epoch: 500, cost: 0.05314202979207039\n",
            "epoch: 600, cost: 0.041332367807626724\n",
            "epoch: 700, cost: 0.033082395792007446\n",
            "epoch: 800, cost: 0.027084778994321823\n",
            "epoch: 900, cost: 0.022583408281207085\n",
            "epoch: 1000, cost: 0.01911536045372486\n",
            "epoch: 1100, cost: 0.016384445130825043\n",
            "epoch: 1200, cost: 0.014193632639944553\n",
            "epoch: 1300, cost: 0.012407924048602581\n",
            "epoch: 1400, cost: 0.010932214558124542\n",
            "epoch: 1500, cost: 0.009697952307760715\n",
            "epoch: 1600, cost: 0.008654617704451084\n",
            "epoch: 1700, cost: 0.0077643683180212975\n",
            "epoch: 1800, cost: 0.006998403929173946\n",
            "epoch: 1900, cost: 0.006334477104246616\n",
            "epoch: 2000, cost: 0.005754970945417881\n",
            "epoch: 2100, cost: 0.005246228538453579\n",
            "epoch: 2200, cost: 0.0047970181331038475\n",
            "epoch: 2300, cost: 0.004398487973958254\n",
            "epoch: 2400, cost: 0.004043188877403736\n",
            "epoch: 2500, cost: 0.003725206246599555\n",
            "epoch: 2600, cost: 0.0034394138492643833\n",
            "epoch: 2700, cost: 0.003181739244610071\n",
            "epoch: 2800, cost: 0.0029486026614904404\n",
            "epoch: 2900, cost: 0.002737026195973158\n",
            "epoch: 3000, cost: 0.00254449644125998\n",
            "tensor([2, 2, 2, 1, 1, 1, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "\n",
        "x_test = torch.FloatTensor([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
        "h_test = torch.softmax(torch.mm(x_test, W) + b, dim=1)\n",
        "print(h_test)\n",
        "print(torch.argmax(h_test, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NHstKfAIAv",
        "outputId": "484efb55-53be-4d52-d7ac-b3e7dfc8d0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e+00, 8.6425e-19, 4.2438e-38],\n",
            "        [1.8032e-03, 8.5748e-01, 1.4072e-01],\n",
            "        [1.1293e-33, 6.5684e-12, 1.0000e+00]])\n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.FloatTensor([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5],\n",
        "                            [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
        "y_train = torch.tensor([2, 2, 2, 1, 1, 1, 0, 0], dtype=torch.long)\n",
        "\n",
        "# W = torch.rand(4, 3, requires_grad=True)\n",
        "# b = torch.rand(1, 3, requires_grad=True)\n",
        "model = nn.Linear(4,3) # W의 크기와 똑같이\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    # h = torch.mm(x_train, W) + b\n",
        "    h = model(x_train)\n",
        "    cost = F.cross_entropy(h, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      if epoch % 100 == 0:\n",
        "        print(f\"epoch: {epoch}, cost: {cost.item()}\")"
      ],
      "metadata": {
        "id": "Heic0takDeHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f714d14-4f36-4c2f-f04a-a365d6368d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 2.077101707458496\n",
            "epoch: 100, cost: 0.34192538261413574\n",
            "epoch: 200, cost: 0.22457635402679443\n",
            "epoch: 300, cost: 0.15560947358608246\n",
            "epoch: 400, cost: 0.11402758955955505\n",
            "epoch: 500, cost: 0.08722130209207535\n",
            "epoch: 600, cost: 0.0688886046409607\n",
            "epoch: 700, cost: 0.055770546197891235\n",
            "epoch: 800, cost: 0.04604986682534218\n",
            "epoch: 900, cost: 0.03864268213510513\n",
            "epoch: 1000, cost: 0.0328669399023056\n",
            "epoch: 1100, cost: 0.02827518619596958\n",
            "epoch: 1200, cost: 0.02456354908645153\n",
            "epoch: 1300, cost: 0.021519947797060013\n",
            "epoch: 1400, cost: 0.01899247244000435\n",
            "epoch: 1500, cost: 0.01687026023864746\n",
            "epoch: 1600, cost: 0.015070663765072823\n",
            "epoch: 1700, cost: 0.01353122666478157\n",
            "epoch: 1800, cost: 0.012203936465084553\n",
            "epoch: 1900, cost: 0.011051386594772339\n",
            "epoch: 2000, cost: 0.010044106282293797\n",
            "epoch: 2100, cost: 0.009158704429864883\n",
            "epoch: 2200, cost: 0.008376318961381912\n",
            "epoch: 2300, cost: 0.0076815467327833176\n",
            "epoch: 2400, cost: 0.007061811164021492\n",
            "epoch: 2500, cost: 0.006506867241114378\n",
            "epoch: 2600, cost: 0.006007918156683445\n",
            "epoch: 2700, cost: 0.005557897500693798\n",
            "epoch: 2800, cost: 0.005150600802153349\n",
            "epoch: 2900, cost: 0.0047809286043047905\n",
            "epoch: 3000, cost: 0.00444446736946702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QRzI-eZ8ddU",
        "outputId": "0ea25541-bd51-47eb-a2e0-a1272821ec4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4, out_features=3, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train = np.array([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5],\n",
        "                    [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
        "y_train = np.array([2, 2, 2, 1, 1, 1, 0, 0])\n",
        "\n",
        "logistic = LogisticRegression(penalty=None)\n",
        "logistic.fit(x_train, y_train)\n",
        "\n",
        "pred = logistic.predict([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnHtQYWw82rW",
        "outputId": "8bb9118b-3ef5-4aa9-dd02-f0a0faccd53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdQwkUMlfRokt62sIKvnox",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}